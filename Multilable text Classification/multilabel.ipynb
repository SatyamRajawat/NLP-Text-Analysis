{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Classs Classification of Classes,Computer Science,Physics,Mathematics,Statistics,Quantitative, Biology,Quantitative Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing dataset of training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') #Loading spacy english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>27853</td>\n",
       "      <td>An Approach for Spatial-temporal Traffic Model...</td>\n",
       "      <td>The volume and types of traffic data in mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>28357</td>\n",
       "      <td>CVXR: An R Package for Disciplined Convex Opti...</td>\n",
       "      <td>CVXR is an R package that provides an object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>24613</td>\n",
       "      <td>Ferromagnetism in chiral multilayer 2D semimetals</td>\n",
       "      <td>We calculate the temperature dependent long-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>27573</td>\n",
       "      <td>A probabilistic gridded product for daily prec...</td>\n",
       "      <td>Gridded data products, for example interpola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>25270</td>\n",
       "      <td>Standard Model - Axion - Seesaw - H portal inf...</td>\n",
       "      <td>Extending the Standard Model with a new comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              TITLE  \\\n",
       "6880  27853  An Approach for Spatial-temporal Traffic Model...   \n",
       "7384  28357  CVXR: An R Package for Disciplined Convex Opti...   \n",
       "3640  24613  Ferromagnetism in chiral multilayer 2D semimetals   \n",
       "6600  27573  A probabilistic gridded product for daily prec...   \n",
       "4297  25270  Standard Model - Axion - Seesaw - H portal inf...   \n",
       "\n",
       "                                               ABSTRACT  \n",
       "6880    The volume and types of traffic data in mobi...  \n",
       "7384    CVXR is an R package that provides an object...  \n",
       "3640    We calculate the temperature dependent long-...  \n",
       "6600    Gridded data products, for example interpola...  \n",
       "4297    Extending the Standard Model with a new comp...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16306</th>\n",
       "      <td>16307</td>\n",
       "      <td>A simple efficient density estimator that enab...</td>\n",
       "      <td>This paper introduces a simple and efficient...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>705</td>\n",
       "      <td>Common change point estimation in panel data f...</td>\n",
       "      <td>We establish the convergence rates and asymp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>17375</td>\n",
       "      <td>A similarity criterion for sequential programs...</td>\n",
       "      <td>The execution of sequential programs allows ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>4598</td>\n",
       "      <td>On central leaves of Hodge-type Shimura variet...</td>\n",
       "      <td>Kisin and Pappas constructed integral models...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13072</th>\n",
       "      <td>13073</td>\n",
       "      <td>Learning Structural Node Embeddings Via Diffus...</td>\n",
       "      <td>Nodes residing in different parts of a graph...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>5288</td>\n",
       "      <td>An Orchestrated Empirical Study on Deep Learni...</td>\n",
       "      <td>Deep learning (DL) has recently achieved tre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945</th>\n",
       "      <td>10946</td>\n",
       "      <td>Temperature induced transition from p-n to n-n...</td>\n",
       "      <td>The transport characteristics across the pul...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17357</th>\n",
       "      <td>17358</td>\n",
       "      <td>Correlations and enlarged superconducting phas...</td>\n",
       "      <td>We compute physical properties across the ph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16117</th>\n",
       "      <td>16118</td>\n",
       "      <td>Absolute spectroscopy near 7.8 μm with a comb-...</td>\n",
       "      <td>We report the first experimental demonstrati...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10470</th>\n",
       "      <td>10471</td>\n",
       "      <td>Designing Deterministic Polynomial-Space Algor...</td>\n",
       "      <td>In recent years, several powerful techniques...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              TITLE  \\\n",
       "16306  16307  A simple efficient density estimator that enab...   \n",
       "704      705  Common change point estimation in panel data f...   \n",
       "17374  17375  A similarity criterion for sequential programs...   \n",
       "4597    4598  On central leaves of Hodge-type Shimura variet...   \n",
       "13072  13073  Learning Structural Node Embeddings Via Diffus...   \n",
       "5287    5288  An Orchestrated Empirical Study on Deep Learni...   \n",
       "10945  10946  Temperature induced transition from p-n to n-n...   \n",
       "17357  17358  Correlations and enlarged superconducting phas...   \n",
       "16117  16118  Absolute spectroscopy near 7.8 μm with a comb-...   \n",
       "10470  10471  Designing Deterministic Polynomial-Space Algor...   \n",
       "\n",
       "                                                ABSTRACT  Computer Science  \\\n",
       "16306    This paper introduces a simple and efficient...                 1   \n",
       "704      We establish the convergence rates and asymp...                 0   \n",
       "17374    The execution of sequential programs allows ...                 1   \n",
       "4597     Kisin and Pappas constructed integral models...                 0   \n",
       "13072    Nodes residing in different parts of a graph...                 1   \n",
       "5287     Deep learning (DL) has recently achieved tre...                 1   \n",
       "10945    The transport characteristics across the pul...                 0   \n",
       "17357    We compute physical properties across the ph...                 0   \n",
       "16117    We report the first experimental demonstrati...                 0   \n",
       "10470    In recent years, several powerful techniques...                 1   \n",
       "\n",
       "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "16306        0            0           1                     0   \n",
       "704          0            1           1                     0   \n",
       "17374        0            0           0                     0   \n",
       "4597         0            1           0                     0   \n",
       "13072        0            0           1                     0   \n",
       "5287         0            0           0                     0   \n",
       "10945        1            0           0                     0   \n",
       "17357        1            0           0                     0   \n",
       "16117        1            0           0                     0   \n",
       "10470        0            0           0                     0   \n",
       "\n",
       "       Quantitative Finance  \n",
       "16306                     0  \n",
       "704                       0  \n",
       "17374                     0  \n",
       "4597                      0  \n",
       "13072                     0  \n",
       "5287                      0  \n",
       "10945                     0  \n",
       "17357                     0  \n",
       "16117                     0  \n",
       "10470                     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20972\n",
      "8989\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20972.000000</td>\n",
       "      <td>20972.000000</td>\n",
       "      <td>20972.000000</td>\n",
       "      <td>20972.000000</td>\n",
       "      <td>20972.000000</td>\n",
       "      <td>20972.000000</td>\n",
       "      <td>20972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10486.500000</td>\n",
       "      <td>0.409784</td>\n",
       "      <td>0.286716</td>\n",
       "      <td>0.267881</td>\n",
       "      <td>0.248236</td>\n",
       "      <td>0.027990</td>\n",
       "      <td>0.011873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6054.239259</td>\n",
       "      <td>0.491806</td>\n",
       "      <td>0.452238</td>\n",
       "      <td>0.442866</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.164947</td>\n",
       "      <td>0.108317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5243.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10486.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15729.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20972.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Computer Science       Physics   Mathematics  \\\n",
       "count  20972.000000      20972.000000  20972.000000  20972.000000   \n",
       "mean   10486.500000          0.409784      0.286716      0.267881   \n",
       "std     6054.239259          0.491806      0.452238      0.442866   \n",
       "min        1.000000          0.000000      0.000000      0.000000   \n",
       "25%     5243.750000          0.000000      0.000000      0.000000   \n",
       "50%    10486.500000          0.000000      0.000000      0.000000   \n",
       "75%    15729.250000          1.000000      1.000000      1.000000   \n",
       "max    20972.000000          1.000000      1.000000      1.000000   \n",
       "\n",
       "         Statistics  Quantitative Biology  Quantitative Finance  \n",
       "count  20972.000000          20972.000000          20972.000000  \n",
       "mean       0.248236              0.027990              0.011873  \n",
       "std        0.432000              0.164947              0.108317  \n",
       "min        0.000000              0.000000              0.000000  \n",
       "25%        0.000000              0.000000              0.000000  \n",
       "50%        0.000000              0.000000              0.000000  \n",
       "75%        0.000000              0.000000              0.000000  \n",
       "max        1.000000              1.000000              1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['TITLE'] + train['ABSTRACT']\n",
    "test['text'] = test['TITLE'] + test['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.drop(['TITLE', 'ABSTRACT'],axis = 1)\n",
    "test_df = test.drop(['TITLE', 'ABSTRACT'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps  P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rotation Invariance Neural Network  Rotation i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Computer Science  Physics  Mathematics  Statistics  \\\n",
       "0   1                 1        0            0           0   \n",
       "1   2                 1        0            0           0   \n",
       "2   3                 0        0            1           0   \n",
       "3   4                 0        0            1           0   \n",
       "4   5                 1        0            0           1   \n",
       "\n",
       "   Quantitative Biology  Quantitative Finance  \\\n",
       "0                     0                     0   \n",
       "1                     0                     0   \n",
       "2                     0                     0   \n",
       "3                     0                     0   \n",
       "4                     0                     0   \n",
       "\n",
       "                                                text  \n",
       "0  Reconstructing Subject-Specific Effect Maps  P...  \n",
       "1  Rotation Invariance Neural Network  Rotation i...  \n",
       "2  Spherical polyharmonics and Poisson kernels fo...  \n",
       "3  A finite element approximation for the stochas...  \n",
       "4  Comparative study of Discrete Wavelet Transfor...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      0\n",
       "Computer Science        0\n",
       "Physics                 0\n",
       "Mathematics             0\n",
       "Statistics              0\n",
       "Quantitative Biology    0\n",
       "Quantitative Finance    0\n",
       "text                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Reconstructing Subject-Specific Effect Maps  Predictive models allow subject-specific inference when analyzing disease\\nrelated alterations in neuroimaging data. Given a subject's data, inference can\\nbe made at two levels: global, i.e. identifiying condition presence for the\\nsubject, and local, i.e. detecting condition effect on each individual\\nmeasurement extracted from the subject's data. While global inference is widely\\nused, local inference, which can be used to form subject-specific effect maps,\\nis rarely used because existing models often yield noisy detections composed of\\ndispersed isolated islands. In this article, we propose a reconstruction\\nmethod, named RSM, to improve subject-specific detections of predictive\\nmodeling approaches and in particular, binary classifiers. RSM specifically\\naims to reduce noise due to sampling error associated with using a finite\\nsample of examples to train classifiers. The proposed method is a wrapper-type\\nalgorithm that can be used with different binary classifiers in a diagnostic\\nmanner, i.e. without information on condition presence. Reconstruction is posed\\nas a Maximum-A-Posteriori problem with a prior model whose parameters are\\nestimated from training data in a classifier-specific fashion. Experimental\\nevaluation is performed on synthetically generated data and data from the\\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database. Results on\\nsynthetic data demonstrate that using RSM yields higher detection accuracy\\ncompared to using models directly or with bootstrap averaging. Analyses on the\\nADNI dataset show that RSM can also improve correlation between\\nsubject-specific detections in cortical thickness data and non-imaging markers\\nof Alzheimer's Disease (AD), such as the Mini Mental State Examination Score\\nand Cerebrospinal Fluid amyloid-$\\\\beta$ levels. Further reliability studies on\\nthe longitudinal ADNI dataset show improvement on detection reliability when\\nRSM is used.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text function\n",
    "import string\n",
    "punct = string.punctuation\n",
    "\n",
    "def text_clean(text):\n",
    "    text = text.lower()  #Convert text in lower case\n",
    "    text = text.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    punc_removed = [char for char in text if char not in punct]  #Removing Punctuations\n",
    "    punc_removed_join = ''.join(punc_removed) \n",
    "    \n",
    "    doc= nlp(punc_removed_join)\n",
    "    text_out = [token.lemma_ for token in doc if token.is_stop == False and token.is_alpha and len(token)>2]\n",
    "    txt = ' '.join(text_out)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reconstruct subjectspecific effect map predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rotation invariance neural network rotation in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spherical polyharmonics poisson kernel polyhar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>finite element approximation stochastic maxwel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>comparative study discrete wavelet transform w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20967</th>\n",
       "      <td>20968</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>contemporary machine learn guide practitioner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20968</th>\n",
       "      <td>20969</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>uniform diamond coating wcco hard alloy cut in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20969</th>\n",
       "      <td>20970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>analyse soccer game clustering conceptor prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20970</th>\n",
       "      <td>20971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>efficient simulation lefttail sum correlate lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971</th>\n",
       "      <td>20972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>optional stopping problem bayesian recently op...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20972 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Computer Science  Physics  Mathematics  Statistics  \\\n",
       "0          1                 1        0            0           0   \n",
       "1          2                 1        0            0           0   \n",
       "2          3                 0        0            1           0   \n",
       "3          4                 0        0            1           0   \n",
       "4          5                 1        0            0           1   \n",
       "...      ...               ...      ...          ...         ...   \n",
       "20967  20968                 1        1            0           0   \n",
       "20968  20969                 0        1            0           0   \n",
       "20969  20970                 1        0            0           0   \n",
       "20970  20971                 0        0            1           1   \n",
       "20971  20972                 0        0            1           1   \n",
       "\n",
       "       Quantitative Biology  Quantitative Finance  \\\n",
       "0                         0                     0   \n",
       "1                         0                     0   \n",
       "2                         0                     0   \n",
       "3                         0                     0   \n",
       "4                         0                     0   \n",
       "...                     ...                   ...   \n",
       "20967                     0                     0   \n",
       "20968                     0                     0   \n",
       "20969                     0                     0   \n",
       "20970                     0                     0   \n",
       "20971                     0                     0   \n",
       "\n",
       "                                                    text  \n",
       "0      reconstruct subjectspecific effect map predict...  \n",
       "1      rotation invariance neural network rotation in...  \n",
       "2      spherical polyharmonics poisson kernel polyhar...  \n",
       "3      finite element approximation stochastic maxwel...  \n",
       "4      comparative study discrete wavelet transform w...  \n",
       "...                                                  ...  \n",
       "20967  contemporary machine learn guide practitioner ...  \n",
       "20968  uniform diamond coating wcco hard alloy cut in...  \n",
       "20969  analyse soccer game clustering conceptor prese...  \n",
       "20970  efficient simulation lefttail sum correlate lo...  \n",
       "20971  optional stopping problem bayesian recently op...  \n",
       "\n",
       "[20972 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>closedform marginal likelihood gammapoisson ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>laboratory midir spectra equilibrate igneous m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>case static amsdu aggregation wlans frame aggr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>gaiaeso survey inner disk intermediateage open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>witnessfunction versus interpretationfunction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>29957</td>\n",
       "      <td>support mixeddatatype matrix multiplication bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>29958</td>\n",
       "      <td>axiomatic basis blackwell optimality theory ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>29959</td>\n",
       "      <td>genevis interactive visualization tool combine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>29960</td>\n",
       "      <td>quantify causal effect speed camera road traff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>29961</td>\n",
       "      <td>cubemagic labeling grid vertex edge ddimension...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text\n",
       "0     20973  closedform marginal likelihood gammapoisson ma...\n",
       "1     20974  laboratory midir spectra equilibrate igneous m...\n",
       "2     20975  case static amsdu aggregation wlans frame aggr...\n",
       "3     20976  gaiaeso survey inner disk intermediateage open...\n",
       "4     20977  witnessfunction versus interpretationfunction ...\n",
       "...     ...                                                ...\n",
       "8984  29957  support mixeddatatype matrix multiplication bl...\n",
       "8985  29958  axiomatic basis blackwell optimality theory ma...\n",
       "8986  29959  genevis interactive visualization tool combine...\n",
       "8987  29960  quantify causal effect speed camera road traff...\n",
       "8988  29961  cubemagic labeling grid vertex edge ddimension...\n",
       "\n",
       "[8989 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'] = test_df['text'].apply(text_clean)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']\n"
     ]
    }
   ],
   "source": [
    "col = list(train_df.columns)\n",
    "target = col[1:7]\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science  Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0                 1        0            0           0                     0   \n",
       "1                 1        0            0           0                     0   \n",
       "2                 0        0            1           0                     0   \n",
       "3                 0        0            1           0                     0   \n",
       "4                 1        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train_df[target]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 3\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "y.sum(axis=0).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['text'], y, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abelian', 'ability', 'able', 'absence', 'absolute', 'absorption', 'abstract', 'abundance', 'accelerate', 'acceleration', 'access', 'accord', 'account', 'accretion', 'accuracy', 'accurate', 'accurately', 'achieve', 'acoustic', 'acquire', 'acquisition', 'act', 'action', 'activation', 'active', 'activity', 'actual', 'adapt', 'adaptation', 'adaptive', 'add', 'addition', 'additional', 'additionally', 'additive', 'address', 'address problem', 'admit', 'adopt', 'advance', 'advanced', 'advantage', 'adversarial', 'adversarial example', 'adversarial network', 'affect', 'affine', 'age', 'agent', 'aggregate', 'agn', 'agree', 'agreement', 'aim', 'algebra', 'algebraic', 'algebras', 'algorithm', 'algorithm base', 'algorithmic', 'algorithms', 'alignment', 'allocation', 'allow', 'alpha', 'alternate', 'alternative', 'amplitude', 'analogous', 'analogue', 'analyse', 'analysis', 'analytic', 'analytical', 'analytically', 'analyze', 'andor', 'angle', 'angular', 'anisotropic', 'anisotropy', 'annotation', 'anomalous', 'anomaly', 'answer', 'antenna', 'appear', 'appearance', 'applicability', 'applicable', 'application', 'apply', 'approach', 'approach base', 'appropriate', 'approximate', 'approximately', 'approximation', 'arbitrary', 'architecture', 'area', 'argue', 'argument', 'arise', 'arithmetic', 'arm', 'array', 'art', 'article', 'artificial', 'ask', 'aspect', 'assess', 'assessment', 'assign', 'assignment', 'associate', 'associated', 'association', 'assume', 'assumption', 'asymmetric', 'asymptotic', 'asymptotically', 'atmosphere', 'atmospheric', 'atom', 'atomic', 'attack', 'attempt', 'attention', 'attract', 'attribute', 'audio', 'augment', 'author', 'autoencoder', 'automata', 'automate', 'automatic', 'automatically', 'autonomous', 'auxiliary', 'availability', 'available', 'average', 'avoid', 'away', 'axis', 'background', 'bad', 'balance', 'ball', 'band', 'bandit', 'bandwidth', 'barrier', 'base', 'baseline', 'basic', 'basis', 'batch', 'battery', 'bayesian', 'beam', 'behavior', 'behaviour', 'belief', 'believe', 'belong', 'benchmark', 'benefit', 'beta', 'bias', 'big', 'big datum', 'binary', 'bind', 'biological', 'bit', 'black', 'black hole', 'blackbox', 'block', 'body', 'boltzmann', 'bond', 'boolean', 'boost', 'bootstrap', 'bound', 'boundary', 'boundary condition', 'box', 'brain', 'branch', 'break', 'bridge', 'bring', 'broad', 'brownian', 'build', 'building', 'bulk', 'bundle', 'cache', 'calculate', 'calculation', 'calculus', 'calibration', 'call', 'camera', 'cancer', 'candidate', 'canonical', 'capability', 'capable', 'capacity', 'capture', 'carbon', 'carlo', 'carrier', 'carry', 'cascade', 'case', 'case study', 'category', 'causal', 'cause', 'cavity', 'cell', 'cellular', 'center', 'central', 'certain', 'chain', 'challenge', 'challenging', 'change', 'channel', 'chaotic', 'character', 'characteristic', 'characterization', 'characterize', 'charge', 'check', 'chemical', 'choice', 'choose', 'circuit', 'circular', 'citation', 'city', 'claim', 'class', 'classic', 'classical', 'classification', 'classifier', 'classify', 'clear', 'clinical', 'close', 'closed', 'closely', 'cloud', 'cluster', 'clustering', 'cnn', 'code', 'coefficient', 'cognitive', 'coherence', 'coherent', 'cohomology', 'coincide', 'cold', 'collapse', 'collect', 'collection', 'collective', 'collision', 'color', 'combination', 'combinatorial', 'combine', 'come', 'common', 'commonly', 'communication', 'community', 'community detection', 'compact', 'company', 'comparable', 'compare', 'comparison', 'compatible', 'compete', 'competitive', 'complement', 'complete', 'completely', 'completion', 'complex', 'complexity', 'component', 'compose', 'composite', 'composition', 'compound', 'comprehensive', 'compression', 'comprise', 'computation', 'computational', 'computational complexity', 'computationally', 'compute', 'computer', 'computer vision', 'computing', 'concentration', 'concept', 'concern', 'conclude', 'conclusion', 'condition', 'conditional', 'conduct', 'conductivity', 'cone', 'confidence', 'confidence interval', 'configuration', 'confirm', 'conformal', 'conjecture', 'connect', 'connected', 'connection', 'connectivity', 'consensus', 'consequence', 'consequently', 'conservation', 'consider', 'consider problem', 'consideration', 'consist', 'consistency', 'consistent', 'consistently', 'constant', 'constitute', 'constrain', 'constraint', 'construct', 'construction', 'consumption', 'contact', 'contain', 'content', 'context', 'continue', 'continuous', 'continuum', 'contrast', 'contribute', 'contribution', 'control', 'controller', 'conventional', 'converge', 'convergence', 'convergence rate', 'convex', 'convolution', 'convolutional', 'convolutional neural', 'convolutional neural network', 'cool', 'cooperative', 'coordinate', 'core', 'corpus', 'correct', 'correction', 'correlate', 'correlation', 'correspond', 'correspondence', 'corresponding', 'cosmic', 'cosmological', 'cost', 'count', 'counterpart', 'couple', 'coupling', 'covariance', 'covariance matrix', 'covariate', 'cover', 'coverage', 'create', 'criterion', 'critical', 'cross', 'crucial', 'crystal', 'cubic', 'current', 'currently', 'curvature', 'curve', 'customer', 'cycle', 'cyclic', 'dark', 'dark matter', 'data', 'data set', 'database', 'datadriven', 'dataset', 'date', 'datum', 'datum analysis', 'datum set', 'day', 'deal', 'decade', 'decay', 'decide', 'decision', 'decode', 'decomposition', 'decrease', 'deduce', 'deep', 'deep convolutional', 'deep learning', 'deep network', 'deep neural', 'deep neural network', 'deep reinforcement', 'defect', 'define', 'definition', 'deformation', 'degree', 'degree freedom', 'delay', 'deliver', 'delta', 'demand', 'demonstrate', 'demonstrate effectiveness', 'demonstration', 'denote', 'dense', 'density', 'density functional', 'depend', 'dependence', 'dependency', 'dependent', 'deploy', 'depth', 'derivation', 'derivative', 'derive', 'descent', 'describe', 'description', 'design', 'desire', 'despite', 'detail', 'detailed', 'detect', 'detection', 'detector', 'determination', 'determine', 'deterministic', 'develop', 'developer', 'development', 'deviation', 'device', 'diagram', 'dictionary', 'dielectric', 'differ', 'difference', 'different', 'different type', 'differential', 'differential equation', 'difficult', 'difficulty', 'diffraction', 'diffusion', 'digital', 'dimension', 'dimensional', 'dimensionality', 'dipole', 'dirac', 'direct', 'direction', 'directly', 'dirichlet', 'disc', 'discover', 'discovery', 'discrete', 'discretization', 'discuss', 'discussion', 'disease', 'disk', 'disorder', 'dispersion', 'display', 'distance', 'distinct', 'distinguish', 'distortion', 'distribute', 'distribution', 'disturbance', 'divergence', 'diverse', 'diversity', 'divide', 'dna', 'dnn', 'document', 'domain', 'dominant', 'dominate', 'double', 'draw', 'drift', 'drive', 'droplet', 'drug', 'dual', 'duality', 'duration', 'dust', 'dwarf', 'dynamic', 'dynamical', 'dynamical system', 'dynamically', 'early', 'earth', 'easily', 'easy', 'economic', 'edge', 'effect', 'effective', 'effectively', 'effectiveness', 'efficacy', 'efficiency', 'efficient', 'efficiently', 'effort', 'eigenvalue', 'elastic', 'electric', 'electrical', 'electromagnetic', 'electron', 'electronic', 'element', 'elementary', 'elliptic', 'embed', 'embedding', 'emerge', 'emergence', 'emission', 'empirical', 'empirically', 'employ', 'enable', 'encode', 'end', 'endtoend', 'energy', 'engine', 'engineering', 'enhance', 'enhancement', 'ensemble', 'ensure', 'entanglement', 'entire', 'entity', 'entropy', 'entry', 'environment', 'environmental', 'epidemic', 'equal', 'equation', 'equilibrium', 'equip', 'equivalence', 'equivalent', 'error', 'especially', 'essential', 'essentially', 'establish', 'estimate', 'estimation', 'estimator', 'etc', 'euclidean', 'euler', 'evaluate', 'evaluation', 'event', 'evidence', 'evolution', 'evolutionary', 'evolve', 'exact', 'exactly', 'examine', 'example', 'exceed', 'excellent', 'exchange', 'excitation', 'execution', 'exhibit', 'exist', 'exist method', 'existence', 'exoplanet', 'expand', 'expansion', 'expect', 'expectation', 'expensive', 'experience', 'experiment', 'experimental', 'experimental result', 'experimentally', 'expert', 'explain', 'explanation', 'explicit', 'explicitly', 'exploit', 'exploration', 'explore', 'exponent', 'exponential', 'exponentially', 'express', 'expression', 'extend', 'extended', 'extension', 'extensive', 'extent', 'external', 'extract', 'extraction', 'extreme', 'extremely', 'face', 'facilitate', 'fact', 'factor', 'factorization', 'fail', 'failure', 'fairness', 'false', 'family', 'far', 'fast', 'fault', 'feasible', 'feature', 'feedback', 'fermi', 'fermion', 'ferromagnetic', 'few', 'fiber', 'field', 'field theory', 'file', 'fill', 'film', 'filter', 'filtering', 'final', 'finally', 'financial', 'find', 'finding', 'finite', 'finitely', 'firstorder', 'fit', 'fitting', 'fix', 'flat', 'flexibility', 'flexible', 'flow', 'fluctuation', 'fluid', 'flux', 'focus', 'follow', 'force', 'forecast', 'forecasting', 'forest', 'form', 'formal', 'formalism', 'formation', 'formula', 'formulate', 'formulation', 'forward', 'fourier', 'fraction', 'fractional', 'frame', 'framework', 'free', 'freedom', 'frequency', 'fully', 'function', 'functional', 'fundamental', 'furthermore', 'fusion', 'future', 'gain', 'galactic', 'galaxy', 'game', 'gamma', 'gan', 'gap', 'gas', 'gate', 'gauge', 'gaussian', 'gaussian process', 'gene', 'general', 'generalization', 'generalize', 'generalized', 'generally', 'generate', 'generation', 'generative', 'generative adversarial', 'generative adversarial network', 'generative model', 'generator', 'generic', 'genetic', 'geodesic', 'geometric', 'geometry', 'giant', 'give', 'glass', 'global', 'go', 'goal', 'good', 'govern', 'gradient', 'gradient descent', 'grain', 'graph', 'graphene', 'graphical', 'graphs', 'gravitational', 'gravity', 'great', 'greatly', 'greedy', 'grid', 'ground', 'ground state', 'group', 'grow', 'growth', 'guarantee', 'guide', 'half', 'hall', 'halo', 'hamiltonian', 'hand', 'handle', 'hard', 'hardware', 'harmonic', 'have', 'health', 'heat', 'heavy', 'height', 'help', 'heterogeneous', 'heuristic', 'hidden', 'hide', 'hierarchical', 'hierarchy', 'high', 'high dimensional', 'high order', 'highdimensional', 'highlevel', 'highlight', 'highly', 'hilbert', 'history', 'hold', 'hole', 'homogeneous', 'homology', 'homotopy', 'horizon', 'host', 'hot', 'human', 'hybrid', 'hydrodynamic', 'hydrogen', 'hyperbolic', 'hyperparameter', 'hypersurface', 'hypothesis', 'idea', 'ideal', 'identification', 'identify', 'identity', 'iii', 'illustrate', 'image', 'imaging', 'impact', 'implement', 'implementation', 'implication', 'implicit', 'imply', 'importance', 'important', 'impose', 'improve', 'improve performance', 'improved', 'improvement', 'include', 'incorporate', 'increase', 'increasingly', 'independence', 'independent', 'independently', 'index', 'indicate', 'indicator', 'individual', 'induce', 'industrial', 'industry', 'inequality', 'infer', 'inference', 'infinite', 'infinity', 'influence', 'information', 'infrastructure', 'inherent', 'initial', 'inner', 'input', 'inside', 'insight', 'inspire', 'instability', 'instance', 'instead', 'instrument', 'insulator', 'integer', 'integrable', 'integral', 'integrate', 'integration', 'intelligence', 'intensity', 'interact', 'interaction', 'interactive', 'interest', 'interesting', 'interface', 'interference', 'intermediate', 'internal', 'internet', 'interpret', 'interpretable', 'interpretation', 'intersection', 'interval', 'intrinsic', 'introduce', 'introduce new', 'introduction', 'invariance', 'invariant', 'inverse', 'inverse problem', 'inversion', 'investigate', 'investigation', 'involve', 'ion', 'irreducible', 'issue', 'item', 'iteration', 'iterative', 'joint', 'jointly', 'jump', 'kernel', 'key', 'kind', 'kinetic', 'knot', 'know', 'knowledge', 'label', 'laboratory', 'lack', 'lagrangian', 'lambda', 'landscape', 'language', 'laplacian', 'large', 'large number', 'large scale', 'largescale', 'laser', 'lasso', 'late', 'latent', 'lattice', 'law', 'layer', 'lead', 'learn', 'learn algorithm', 'learning', 'learning algorithm', 'learning method', 'learning model', 'learning technique', 'leave', 'length', 'leq', 'let', 'level', 'leverage', 'library', 'lie', 'life', 'lifetime', 'light', 'like', 'likelihood', 'likely', 'limit', 'limitation', 'limited', 'line', 'linear', 'linearly', 'link', 'lipschitz', 'liquid', 'list', 'literature', 'little', 'load', 'local', 'localization', 'localize', 'locally', 'locate', 'location', 'log', 'logarithmic', 'logic', 'logistic', 'long', 'longitudinal', 'longrange', 'longterm', 'look', 'loop', 'loss', 'loss function', 'low', 'low bind', 'low bound', 'lowdimensional', 'lower', 'lowrank', 'lstm', 'luminosity', 'machine', 'machine learn', 'machine learning', 'magnetic', 'magnetic field', 'magnetization', 'magnitude', 'main', 'main result', 'mainly', 'maintain', 'major', 'majority', 'make', 'management', 'manifold', 'manipulation', 'manner', 'manybody', 'map', 'mapping', 'marginal', 'market', 'markov', 'markov chain', 'mass', 'masse', 'massive', 'match', 'matching', 'material', 'mathbb', 'mathcal', 'mathematical', 'matrix', 'matter', 'maximal', 'maximization', 'maximize', 'maximum', 'maximum likelihood', 'mean', 'meanfield', 'meaningful', 'measure', 'measurement', 'mechanic', 'mechanical', 'mechanism', 'medical', 'medium', 'meet', 'member', 'memory', 'mesh', 'message', 'metal', 'metallic', 'method', 'method base', 'method propose', 'methodology', 'metric', 'microscopic', 'microscopy', 'migration', 'million', 'minimal', 'minimax', 'minimization', 'minimize', 'minimum', 'mining', 'miss', 'mission', 'mitigate', 'mix', 'mixed', 'mixture', 'mobile', 'mobility', 'mode', 'model', 'model base', 'model parameter', 'modeling', 'modelling', 'modern', 'modification', 'modify', 'modular', 'modulation', 'module', 'molecular', 'molecule', 'moment', 'momentum', 'monitor', 'monitoring', 'monte', 'monte carlo', 'motion', 'motivate', 'move', 'movement', 'multidimensional', 'multilayer', 'multimodal', 'multiple', 'multiplicative', 'multiscale', 'multitask', 'multivariate', 'music', 'mutual', 'name', 'natural', 'natural language', 'naturally', 'nature', 'navigation', 'near', 'nearly', 'necessarily', 'necessary', 'need', 'negative', 'neighbor', 'neighborhood', 'net', 'network', 'network architecture', 'network model', 'neural', 'neural network', 'neuron', 'neutron', 'new', 'new approach', 'new method', 'news', 'node', 'noise', 'noisy', 'nonconvex', 'nonlinear', 'nonlocal', 'nonnegative', 'nonparametric', 'nontrivial', 'nonzero', 'norm', 'normal', 'note', 'notion', 'novel', 'novel approach', 'nuclear', 'nucleus', 'null', 'number', 'numerical', 'numerical experiment', 'numerical result', 'numerical simulation', 'numerically', 'numerous', 'object', 'objective', 'objective function', 'observable', 'observation', 'observational', 'observe', 'observed', 'obstacle', 'obtain', 'occur', 'offer', 'omega', 'one', 'onedimensional', 'online', 'open', 'operate', 'operation', 'operational', 'operator', 'opinion', 'opportunity', 'optical', 'optimal', 'optimal control', 'optimality', 'optimization', 'optimization problem', 'optimize', 'optimum', 'option', 'oracle', 'orbit', 'orbital', 'order', 'order magnitude', 'ordinary', 'orientation', 'origin', 'original', 'originate', 'orthogonal', 'oscillation', 'oscillator', 'outcome', 'outlier', 'outperform', 'output', 'overall', 'overcome', 'overhead', 'overlap', 'overview', 'oxygen', 'package', 'packet', 'pair', 'pairwise', 'paper', 'paper consider', 'paper describe', 'paper introduce', 'paper investigate', 'paper present', 'paper propose', 'paper propose novel', 'paper provide', 'paper study', 'parabolic', 'paradigm', 'parallel', 'parameter', 'parametric', 'part', 'partial', 'partially', 'participant', 'particle', 'particular', 'particularly', 'partition', 'pass', 'past', 'patch', 'path', 'patient', 'pattern', 'peak', 'penalty', 'people', 'perception', 'perfect', 'perform', 'performance', 'period', 'periodic', 'permutation', 'perspective', 'perturbation', 'phase', 'phase transition', 'phenomenon', 'phonon', 'photometric', 'photon', 'photonic', 'physical', 'physics', 'picture', 'pipeline', 'pixel', 'place', 'plan', 'planar', 'plane', 'planet', 'planetary', 'planning', 'plasma', 'platform', 'play', 'player', 'point', 'poisson', 'polarization', 'policy', 'polynomial', 'poor', 'popular', 'population', 'portfolio', 'pose', 'position', 'positive', 'possess', 'possibility', 'possible', 'possibly', 'post', 'posterior', 'potential', 'potentially', 'power', 'powerful', 'practical', 'practice', 'precise', 'precisely', 'precision', 'predict', 'prediction', 'predictive', 'predictor', 'preference', 'preliminary', 'presence', 'present', 'present new', 'present novel', 'preserve', 'pressure', 'prevent', 'previous', 'previous work', 'previously', 'price', 'primary', 'prime', 'principal', 'principal component', 'principle', 'prior', 'privacy', 'private', 'probabilistic', 'probability', 'probability distribution', 'probe', 'problem', 'procedure', 'process', 'processing', 'produce', 'product', 'production', 'profile', 'program', 'programming', 'progress', 'project', 'projection', 'projective', 'promise', 'promising', 'proof', 'propagate', 'propagation', 'proper', 'property', 'proportional', 'proposal', 'propose', 'propose algorithm', 'propose approach', 'propose framework', 'propose method', 'propose model', 'propose new', 'propose novel', 'protect', 'protein', 'protocol', 'prototype', 'prove', 'provide', 'public', 'publicly', 'publicly available', 'publish', 'pulse', 'pure', 'purely', 'purpose', 'quadratic', 'qualitative', 'quality', 'quantify', 'quantitative', 'quantity', 'quantization', 'quantum', 'query', 'question', 'quickly', 'quotient', 'radial', 'radiation', 'radio', 'radius', 'raise', 'random', 'random variable', 'random walk', 'randomized', 'randomly', 'range', 'rank', 'rapid', 'rapidly', 'rate', 'ratio', 'rational', 'raw', 'reach', 'reaction', 'real', 'real datum', 'real world', 'realistic', 'realization', 'realize', 'realtime', 'realworld', 'reason', 'receive', 'receiver', 'recent', 'recent work', 'recent year', 'recently', 'recently propose', 'recognition', 'recognize', 'recommendation', 'reconstruct', 'reconstruction', 'record', 'recover', 'recovery', 'recurrent', 'recurrent neural', 'recurrent neural network', 'redshift', 'reduce', 'reduction', 'refer', 'reference', 'reflect', 'reflection', 'regard', 'regime', 'region', 'regression', 'regression model', 'regret', 'regular', 'regularity', 'regularization', 'reinforcement', 'reinforcement learn', 'reinforcement learning', 'relate', 'related', 'relation', 'relationship', 'relative', 'relatively', 'relativistic', 'relaxation', 'release', 'relevance', 'relevant', 'reliability', 'reliable', 'rely', 'remain', 'remove', 'replace', 'report', 'represent', 'representation', 'representative', 'reproduce', 'require', 'requirement', 'research', 'researcher', 'residual', 'resolution', 'resolve', 'resonance', 'resonant', 'resource', 'respect', 'respectively', 'response', 'restrict', 'restriction', 'result', 'result demonstrate', 'result indicate', 'result obtain', 'result show', 'result suggest', 'retrieval', 'return', 'reveal', 'review', 'revisit', 'reward', 'rich', 'riemannian', 'right', 'rigorous', 'ring', 'rise', 'risk', 'rnn', 'road', 'robot', 'robotic', 'robust', 'robustness', 'role', 'room', 'root', 'rotation', 'route', 'rule', 'run', 'runtime', 'safe', 'safety', 'sample', 'sample size', 'sampling', 'satellite', 'satisfy', 'scalability', 'scalable', 'scalar', 'scale', 'scaling', 'scatter', 'scattering', 'scenario', 'scene', 'scheme', 'schrödinger', 'science', 'scientific', 'score', 'search', 'second', 'secondary', 'secondorder', 'section', 'secure', 'security', 'see', 'seek', 'segment', 'segmentation', 'select', 'selection', 'semantic', 'semiconductor', 'semigroup', 'semimetal', 'sense', 'sensing', 'sensitive', 'sensitivity', 'sensor', 'sentence', 'sentiment', 'separate', 'separation', 'sequence', 'sequential', 'series', 'serve', 'server', 'service', 'set', 'setting', 'setup', 'sgd', 'shape', 'share', 'sharp', 'shear', 'shed', 'shift', 'shock', 'short', 'shortterm', 'show', 'sigma', 'sign', 'signal', 'signature', 'significance', 'significant', 'significantly', 'significantly improve', 'silicon', 'sim', 'similar', 'similarity', 'simple', 'simplify', 'simply', 'simulate', 'simulated', 'simulation', 'simulation result', 'simulation study', 'simultaneous', 'simultaneously', 'single', 'singular', 'singularity', 'site', 'situation', 'size', 'slightly', 'slow', 'small', 'smart', 'smooth', 'socalled', 'social', 'social medium', 'social network', 'soft', 'software', 'solar', 'solid', 'soliton', 'solution', 'solve', 'solve problem', 'solver', 'sound', 'source', 'space', 'spacetime', 'span', 'sparse', 'sparsity', 'spatial', 'spatially', 'spatiotemporal', 'speaker', 'special', 'special case', 'specie', 'specific', 'specifically', 'specification', 'specify', 'spectra', 'spectral', 'spectroscopic', 'spectroscopy', 'spectrum', 'speech', 'speech recognition', 'speed', 'speedup', 'sphere', 'spherical', 'spin', 'spinorbit', 'split', 'splitting', 'spread', 'square', 'stability', 'stabilize', 'stable', 'stack', 'stage', 'standard', 'star', 'star formation', 'start', 'state', 'state art', 'statement', 'stateoftheart', 'stateoftheart method', 'static', 'stationary', 'statistic', 'statistical', 'statistically', 'steady', 'stellar', 'step', 'stochastic', 'stochastic gradient', 'stock', 'storage', 'store', 'strain', 'strategy', 'stream', 'strength', 'stress', 'strictly', 'string', 'strong', 'strongly', 'structural', 'structure', 'structured', 'student', 'study', 'subgraph', 'subgroup', 'subject', 'subsequent', 'subset', 'subspace', 'substantial', 'substantially', 'substrate', 'success', 'successful', 'successfully', 'suffer', 'sufficient', 'sufficient condition', 'sufficiently', 'suggest', 'suitable', 'sum', 'superconducte', 'superconducting', 'superconductivity', 'superconductor', 'superior', 'supervise', 'support', 'support vector', 'suppress', 'surface', 'survey', 'switch', 'symbol', 'symmetric', 'symmetry', 'synchronization', 'synthesis', 'synthesize', 'synthetic', 'system', 'systematic', 'systematically', 'tackle', 'tail', 'take', 'take account', 'target', 'task', 'technical', 'technique', 'technology', 'telescope', 'temperature', 'temporal', 'tend', 'tension', 'tensor', 'term', 'test', 'testing', 'text', 'texture', 'theorem', 'theoretical', 'theoretical result', 'theoretically', 'theory', 'thermal', 'thermodynamic', 'thickness', 'thin', 'thousand', 'threedimensional', 'threshold', 'tight', 'time', 'time series', 'timescale', 'timing', 'tissue', 'tool', 'topic', 'topological', 'topology', 'total', 'trace', 'track', 'tracking', 'tradeoff', 'traditional', 'traffic', 'train', 'training', 'training datum', 'trajectory', 'transfer', 'transform', 'transformation', 'transient', 'transit', 'transition', 'translate', 'translation', 'transmission', 'transmit', 'transport', 'transverse', 'trap', 'travel', 'treat', 'treatment', 'tree', 'trend', 'trial', 'trigger', 'trivial', 'true', 'truth', 'try', 'tune', 'tuning', 'turbulence', 'turbulent', 'turn', 'twitter', 'twodimensional', 'type', 'typical', 'typically', 'uncertainty', 'underlie', 'underlying', 'understand', 'understanding', 'unified', 'uniform', 'uniformly', 'unique', 'unit', 'universal', 'universe', 'unknown', 'unlike', 'unstable', 'unsupervise', 'unsupervised', 'update', 'upper', 'upper bound', 'urban', 'url', 'usage', 'use', 'useful', 'user', 'usual', 'usually', 'utility', 'utilize', 'valid', 'validate', 'validation', 'validity', 'value', 'vanish', 'variability', 'variable', 'variance', 'variant', 'variation', 'variational', 'variety', 'vary', 'vector', 'vehicle', 'velocity', 'verification', 'verify', 'version', 'vertex', 'video', 'view', 'virtual', 'viscosity', 'vision', 'visual', 'visualization', 'volatility', 'voltage', 'volume', 'vortex', 'walk', 'wall', 'water', 'wave', 'wavelength', 'way', 'weak', 'weakly', 'web', 'weight', 'weighted', 'well', 'wellknown', 'weyl', 'white', 'wide', 'wide range', 'widely', 'width', 'wind', 'window', 'wireless', 'word', 'work', 'work present', 'work propose', 'world', 'write', 'xray', 'year', 'yield', 'young', 'zero', 'zone']\n",
      "(15729, 2000)\n",
      "(5243, 2000)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer=TfidfVectorizer(min_df=1, smooth_idf=True, norm=\"l2\",tokenizer=lambda x: x.split(),sublinear_tf=True, ngram_range=(1,3))\n",
    "\n",
    "# X_train_multilabel=vectorizer.fit_transform(X_train)\n",
    "# X_test_multilabel=vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 2000,ngram_range=(1,3) )\n",
    "v_train = vectorizer.fit_transform(X_train)\n",
    "v_test = vectorizer.transform(X_test)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print(v_train.shape)\n",
    "print(v_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = OneVsRestClassifier(SVC()).fit(v_train, y_train)\n",
    "pred = clf.predict(v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score : --> 0.6622162883845126\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score : -->\",accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84      2116\n",
      "           1       0.93      0.82      0.87      1527\n",
      "           2       0.87      0.74      0.80      1428\n",
      "           3       0.83      0.72      0.77      1306\n",
      "           4       0.90      0.11      0.20       167\n",
      "           5       0.89      0.27      0.42        59\n",
      "\n",
      "   micro avg       0.86      0.77      0.81      6603\n",
      "   macro avg       0.87      0.59      0.65      6603\n",
      "weighted avg       0.86      0.77      0.80      6603\n",
      " samples avg       0.82      0.80      0.80      6603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report :\")\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_test = vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8989x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 427587 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = clf.predict(vt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8989, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Computer Science  Physics  Mathematics  Statistics  \\\n",
       "0  20973                 0        0            0           1   \n",
       "1  20974                 0        1            0           0   \n",
       "2  20975                 1        0            0           0   \n",
       "3  20976                 0        1            0           0   \n",
       "4  20977                 1        0            0           0   \n",
       "\n",
       "   Quantitative Biology  Quantitative Finance  \n",
       "0                     0                     0  \n",
       "1                     0                     0  \n",
       "2                     0                     0  \n",
       "3                     0                     0  \n",
       "4                     0                     0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('sample_submission.csv')\n",
    "submission=pd.DataFrame(pred1, columns=['Computer Science','Physics','Mathematics','Statistics','Quantitative Biology','Quantitative Finance'])\n",
    "submission=pd.concat([data['ID'],submission],axis=1)\n",
    "submission.to_csv(\"multi_label_topic.csv\", index=False)\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countvectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_v = CountVectorizer(max_features=1000,ngram_range=(1,3))\n",
    "\n",
    "Xtr = count_v.fit_transform(train_df['text']).toarray()\n",
    "Xtes = count_v.transform(test_df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20972, 15729]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\multiclass.py\", line 81, in _fit_binary\n    estimator.fit(X, y)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 227, in fit\n    X, y = self._validate_data(X, y, accept_sparse='csr',\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n    return f(**kwargs)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 812, in check_X_y\n    check_consistent_length(X, y)\n  File \"C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 255, in check_consistent_length\n    raise ValueError(\"Found input variables with inconsistent numbers of\"\nValueError: Found input variables with inconsistent numbers of samples: [20972, 15729]\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-073d9ff39929>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hinge'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# of spawning threads.  See joblib issue #112.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n\u001b[0m\u001b[0;32m    242\u001b[0m             self.estimator, X, column, classes=[\n\u001b[0;32m    243\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\keras\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20972, 15729]"
     ]
    }
   ],
   "source": [
    "classifier=OneVsRestClassifier(LinearSVC(penalty=\"l2\",loss='hinge'), n_jobs=-1)\n",
    "classifier.fit(Xtr,y_train)\n",
    "predictions=classifier.predict(Xtes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Our Model, Estimator + Multilabel Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmultilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'adapt',\n",
       " 'base',\n",
       " 'problem_transform',\n",
       " 'utils']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(skmultilearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Our Multi-Label Prob to Multi-Class # binary classficiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Label Pkgs\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_clf = BinaryRelevance(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(), require_dense=[True, True])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = binary_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5758105530832803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      2535\n",
      "           1       0.93      0.73      0.82      1849\n",
      "           2       0.84      0.69      0.76      1711\n",
      "           3       0.76      0.57      0.65      1554\n",
      "           4       0.00      0.00      0.00       194\n",
      "           5       0.00      0.00      0.00        67\n",
      "\n",
      "   micro avg       0.82      0.68      0.75      7910\n",
      "   macro avg       0.55      0.46      0.50      7910\n",
      "weighted avg       0.80      0.68      0.73      7910\n",
      " samples avg       0.73      0.72      0.71      7910\n",
      "\n",
      "0.5758105530832803\n",
      "0.7469796341042458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satyam.singh\\anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6489192625556262\n",
      "F1 score =  0.7738752959747435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "lp_classifier = LabelPowerset(LogisticRegression())\n",
    "lp_classifier.fit(X_train, y_train)\n",
    "lp_predictions = lp_classifier.predict(X_test)\n",
    "print(\"Accuracy = \",accuracy_score(y_test,lp_predictions))\n",
    "print(\"F1 score = \",f1_score(y_test,lp_predictions, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
